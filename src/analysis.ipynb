{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis the basic statistics of reply network\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import networkx as nx\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def generate_network(nodes):\n",
    "    \"\"\"\n",
    "    Generate a network graph from a list of nodes with 'id', 'in_reply_to_id', and metadata.\n",
    "\n",
    "    :param nodes: List of dictionaries containing:\n",
    "                  - 'id': Unique identifier for the post\n",
    "                  - 'in_reply_to_id': ID of the parent post this replies to\n",
    "                  - Metadata such as username, like counts, etc.\n",
    "    :return: A NetworkX DiGraph with nodes and edges.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()  # Directed graph to represent reply relationships\n",
    "\n",
    "    for node in tqdm(nodes):\n",
    "        # Add the current node with metadata\n",
    "        G.add_node(\n",
    "            int(node[\"id\"]),\n",
    "            # username=node['account']['username'],\n",
    "            # display_name=node['account']['display_name'],\n",
    "            # verified=node['account']['verified'],\n",
    "            # followers_count=node['account']['followers_count'],\n",
    "            # statuses_count=node['account']['statuses_count'],\n",
    "            # replies_count=node['replies_count'],\n",
    "            # favourites_count=node['favourites_count'],\n",
    "            # reblogs_count=node['reblogs_count'],\n",
    "            # visibility=node['visibility'],\n",
    "            # content=node['content'],\n",
    "            # created_at=node['created_at'],\n",
    "            # language=node['language'],\n",
    "            # sensitive=node['sensitive'],\n",
    "            # mentions=[mention['username'] for mention in node.get('mentions', [])],\n",
    "        )\n",
    "\n",
    "        # If it replies to another node, add an edge\n",
    "        if node[\"in_reply_to_id\"]:\n",
    "            G.add_node(\n",
    "                int(node[\"in_reply_to_id\"])\n",
    "            )  # Add the parent node if it doesn't exist\n",
    "            G.add_edge(int(node[\"in_reply_to_id\"]), int(node[\"id\"]))\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def build_network(graph, thread, parent_id=None):\n",
    "    post = thread[\"post\"]\n",
    "    post_id = post[\"uri\"]  # Use the URI as a unique identifier\n",
    "    graph.add_node(\n",
    "        post_id, text=post[\"record\"][\"text\"], author=post[\"author\"][\"displayName\"]\n",
    "    )\n",
    "\n",
    "    if parent_id:  # If there is a parent, add an edge\n",
    "        graph.add_edge(parent_id, post_id)\n",
    "\n",
    "    # Process replies recursively\n",
    "    for reply in thread.get(\"replies\", []):\n",
    "        build_network(graph, reply, post_id)\n",
    "\n",
    "\n",
    "with open(\"../data/bsky_threads.json\") as f:\n",
    "    bsky = json.load(f)\n",
    "with open(\"../data/ts_threads.json\") as f:\n",
    "    ts = json.load(f)\n",
    "bsky_network = nx.DiGraph()\n",
    "error_count = 0\n",
    "# Build the graph\n",
    "for thread in tqdm(bsky):\n",
    "    try:\n",
    "        build_network(bsky_network, thread[\"thread\"])\n",
    "    except:\n",
    "        error_count += 1\n",
    "\n",
    "\n",
    "# Generate the network graph\n",
    "ts_network = generate_network(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def calculate_cascade_statistics(graph):\n",
    "    \"\"\"\n",
    "    Calculate cascade statistics for each tree (connected component) in a directed graph.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "        graph (nx.DiGraph): A directed graph representing the network.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries with cascade statistics for each tree.\n",
    "    \"\"\"\n",
    "    if not isinstance(graph, nx.DiGraph):\n",
    "        raise ValueError(\"The input graph must be a directed graph (DiGraph).\")\n",
    "\n",
    "    # Find all connected components (trees) in the directed graph\n",
    "    components = list(nx.weakly_connected_components(graph))\n",
    "\n",
    "    cascade_stats = []\n",
    "    for i, component in enumerate(components):\n",
    "        # Extract the subgraph for this component\n",
    "        tree = graph.subgraph(component)\n",
    "\n",
    "        # Calculate size\n",
    "        size = len(tree.nodes)\n",
    "\n",
    "        # Calculate depth\n",
    "        roots = [node for node in tree.nodes if tree.in_degree(node) == 0]\n",
    "        if len(roots) > 1:\n",
    "            raise ValueError(\"Multiple roots found in the tree.\")\n",
    "        depth = 0\n",
    "        if roots:\n",
    "            for root in roots:\n",
    "                depths = nx.single_source_shortest_path_length(tree, root).values()\n",
    "                depth = max(depth, *depths)\n",
    "\n",
    "        # Calculate maximum breadth\n",
    "        breadth_levels = defaultdict(int)\n",
    "        for node in tree.nodes:\n",
    "            try:\n",
    "                level = nx.shortest_path_length(tree, roots[0], node)\n",
    "                breadth_levels[level] += 1\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue  # Node is unreachable\n",
    "\n",
    "        max_breadth = max(breadth_levels.values()) if breadth_levels else 0\n",
    "\n",
    "        # Calculate structural virality\n",
    "        if len(tree.nodes) > 1:\n",
    "            shortest_paths = nx.shortest_path_length(tree)\n",
    "            virality = mean(\n",
    "                [mean(lengths.values()) for _, lengths in shortest_paths if lengths]\n",
    "            )\n",
    "        else:\n",
    "            virality = 0  # Single node has no structural virality\n",
    "\n",
    "        cascade_stats.append(\n",
    "            {\n",
    "                \"root_id\": roots[0],\n",
    "                \"size\": size,\n",
    "                \"depth\": depth,\n",
    "                \"max_breadth\": max_breadth,\n",
    "                \"structural_virality\": virality,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return cascade_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsky_stats = calculate_cascade_statistics(bsky_network)\n",
    "ts_stats = calculate_cascade_statistics(ts_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_ccdfs(cascade_stats, stat_names):\n",
    "    \"\"\"\n",
    "    Plot grouped CCDFs for multiple statistics in a single figure with a logarithmic y-axis.\n",
    "\n",
    "    Parameters:\n",
    "        cascade_stats (list): List of dictionaries containing cascade statistics.\n",
    "        stat_names (list): List of keys for the statistics to plot (e.g., ['size', 'depth']).\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    n_stats = len(stat_names)\n",
    "    fig, axes = plt.subplots(1, n_stats, figsize=(5 * n_stats, 5), sharey=True)\n",
    "\n",
    "    for i, stat_name in enumerate(stat_names):\n",
    "        # Extract the values for the specified statistic\n",
    "        values = [stat[stat_name] for stat in cascade_stats]\n",
    "\n",
    "        # Sort the values\n",
    "        values = np.array(sorted(values))\n",
    "\n",
    "        # Compute CCDF\n",
    "        ccdf = 1 - np.arange(1, len(values) + 1) / len(values)\n",
    "\n",
    "        # Plot CCDF\n",
    "        ax = axes[i] if n_stats > 1 else axes\n",
    "        ax.step(values, ccdf, where=\"post\")\n",
    "        ax.set_title(f\"CCDF of {stat_name.capitalize()}\", fontsize=14)\n",
    "        ax.set_xlabel(stat_name.capitalize(), fontsize=12)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "        # Set logarithmic y-axis\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_yticks(\n",
    "            [\n",
    "                1,\n",
    "                0.1,\n",
    "                0.01,\n",
    "                0.001,\n",
    "                0.0001,\n",
    "            ]\n",
    "        )\n",
    "        ax.set_yticklabels([\"100%\", \"10%\", \"1%\", \"0.1%\", \"0.01%\"])\n",
    "        ax.get_yaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "\n",
    "    # Set shared y-axis label\n",
    "    fig.supylabel(\"CCDF (Log Scale)\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_ccdfs(bsky_stats, [\"size\", \"depth\", \"max_breadth\", \"structural_virality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ccdfs(ts_stats, [\"size\", \"depth\", \"max_breadth\", \"structural_virality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics\n",
    "bsky_topics = pd.read_csv(\"../data/bsky_df_id_topic.csv\")\n",
    "ts_topics = pd.read_csv(\"../data/ts_df_id_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsky_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsky_stats = (\n",
    "    pd.DataFrame(bsky_stats)\n",
    "    .merge(bsky_topics, left_on=\"root_id\", right_on=\"id\", how=\"left\")\n",
    "    .drop(columns=\"id\")\n",
    ")\n",
    "ts_stats = (\n",
    "    pd.DataFrame(ts_stats)\n",
    "    .merge(ts_topics, left_on=\"root_id\", right_on=\"id\", how=\"left\")\n",
    "    .drop(columns=\"id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Example function to calculate cascade size (can be extended for other stats)\n",
    "def calculate_cascade_stats(df, group_col, stat_col):\n",
    "    \"\"\"\n",
    "    Calculate cascade statistics (e.g., size) by grouping the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with data.\n",
    "        group_col (str): Column to group by (e.g., 'root_id').\n",
    "        stat_col (str): Column to calculate the statistics on (e.g., 'id').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cascade statistics with size and associated topic labels.\n",
    "    \"\"\"\n",
    "    # Group by cascade root_id and calculate size\n",
    "    grouped = (\n",
    "        df.groupby(group_col)\n",
    "        .agg(\n",
    "            {\n",
    "                stat_col: \"count\",  # Count posts in each cascade\n",
    "                \"topic_label\": \"first\",  # Keep the topic label\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    grouped.rename(columns={stat_col: \"size\"}, inplace=True)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "# Plot CCDFs grouped by topic\n",
    "def plot_grouped_ccdfs(cascade_stats, stat_col, group_col):\n",
    "    \"\"\"\n",
    "    Plot grouped CCDFs for a given statistic, grouped by topic labels.\n",
    "\n",
    "    Parameters:\n",
    "        cascade_stats (pd.DataFrame): DataFrame with cascade statistics.\n",
    "        stat_col (str): The statistic column to compute the CCDF for (e.g., 'size').\n",
    "        group_col (str): The column representing the group (e.g., 'topic_label').\n",
    "    \"\"\"\n",
    "    unique_topics = cascade_stats[group_col].unique()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for topic in unique_topics:\n",
    "        # Filter data by topic\n",
    "        topic_data = cascade_stats[cascade_stats[group_col] == topic]\n",
    "        values = topic_data[stat_col].values\n",
    "\n",
    "        # Compute CCDF\n",
    "        values = np.sort(values)\n",
    "        ccdf = 1 - np.arange(1, len(values) + 1) / len(values)\n",
    "\n",
    "        # Plot CCDF\n",
    "        plt.step(values, ccdf, where=\"post\", label=topic)\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Cascade Size (Log Scale)\", fontsize=12)\n",
    "    plt.ylabel(\"CCDF (Log Scale)\", fontsize=12)\n",
    "    plt.title(\"CCDF by Topic\", fontsize=14)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.legend(title=\"Topic Label\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your DataFrame (example)\n",
    "    data = bsky_stats\n",
    "\n",
    "    # Calculate cascade statistics\n",
    "    cascade_stats = calculate_cascade_stats(\n",
    "        data, group_col=\"topic_label\", stat_col=\"size\"\n",
    "    )\n",
    "\n",
    "    # Plot CCDFs grouped by topic\n",
    "    plot_grouped_ccdfs(cascade_stats, stat_col=\"size\", group_col=\"topic_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_stats_by_topic(cascade_stats, stats_to_plot, topic_col):\n",
    "    \"\"\"\n",
    "    Plot statistics grouped by topics using different colors.\n",
    "\n",
    "    Parameters:\n",
    "        cascade_stats (pd.DataFrame): DataFrame with cascade statistics and topics.\n",
    "        stats_to_plot (list): List of statistic columns to plot (e.g., ['size', 'depth']).\n",
    "        topic_col (str): Column representing topics (e.g., 'topic_label').\n",
    "    \"\"\"\n",
    "    unique_topics = cascade_stats[topic_col].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_topics)))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for stat in stats_to_plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for topic, color in zip(unique_topics, colors):\n",
    "            topic_data = cascade_stats[cascade_stats[topic_col] == topic]\n",
    "            values = topic_data[stat].values\n",
    "\n",
    "            # Compute CCDF\n",
    "            values = np.sort(values)\n",
    "            ccdf = 1 - np.arange(1, len(values) + 1) / len(values)\n",
    "\n",
    "            # Plot CCDF for the topic\n",
    "            plt.step(values, ccdf, where=\"post\", label=f\"{topic}\", color=color)\n",
    "\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(f\"{stat.capitalize()} (Log Scale)\", fontsize=12)\n",
    "        plt.ylabel(\"CCDF (Log Scale)\", fontsize=12)\n",
    "        plt.title(f\"CCDF of {stat.capitalize()} by Topic\", fontsize=14)\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "        plt.legend(title=\"Topic\", fontsize=10, bbox_to_anchor=(1.05, 1))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start building the network for the overall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import repost and following data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from cascade_analysis import InformationCascadeGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bsky_reposts.json\") as f:\n",
    "    bsky_repost = json.load(f)\n",
    "\n",
    "with open(\"../data/bsky_follows.json\") as f:\n",
    "    bsky_follow = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/ts_threads.json\") as f:\n",
    "    ts_repost = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cascade_analysis' from '/home/maolee/projects/information-diffusion/src/cascade_analysis.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import cascade_analysis\n",
    "\n",
    "reload(cascade_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "original_list = bsky_follow\n",
    "\n",
    "# Use a defaultdict to store sets of DIDs.\n",
    "merged = defaultdict(set)\n",
    "\n",
    "# chain.from_iterable(...) flattens out the \"dict.items()\" across the list\n",
    "for key, records in chain.from_iterable(item.items() for item in original_list):\n",
    "    # 'records' is the list of dicts. We update the set with the \"did\" values.\n",
    "    merged[key].update(r[\"did\"] for r in records)\n",
    "\n",
    "# Convert to a regular dict if desired:\n",
    "merged_dict = dict(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade_graph = cascade_analysis.InformationCascadeGraph(\n",
    "    bsky_repost, merged_dict, platform=\"bsky\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0a8fb938e444d2ab7855e72ae6829b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Repost Graph:   0%|          | 0/195616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reposts_graph = cascade_graph.build_repost_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379582"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reposts_graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a880327dff43eb9855529e86500c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Reply Graph:   0%|          | 0/195616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reply_graph = cascade_graph.build_reply_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116224"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply_graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990e7b2c2c734efbb5a2a940aad8d578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/116224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The node is not in repost graph\n",
      "The node is not in repost graph\n",
      "The node is not in repost graph\n",
      "The node is not in repost graph\n",
      "The node is not in repost graph\n",
      "Step 2.1: Merged 23138 reply edges into repost edges out of 59813 total reply edges\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e799d36bfed94d2fbce861be2b847148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/183966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_graph = cascade_graph.build_combined_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d1a98b993c494083c5c9863e1f92de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/116224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2.1: Merged 23138 reply edges into repost edges out of 59813 total reply edges\n",
      "Step 2.1: 5 nodes not in repost graph\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac6a6cc86f24512b6719194c72798db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/183966 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_graph = cascade_graph.build_combined_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379587"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edd387e0ea54af7822856e32ff09ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Tree Statistics:   0%|          | 0/79397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb367ebd6fc54f9896f882c2ffb6e9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Tree Statistics:   0%|          | 0/195616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649f3a5814914aac99011ce0e383b8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Tree Statistics:   0%|          | 0/79397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = cascade_graph.calculate_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# build the dataframe, column and row switch\n",
    "\n",
    "combined_stats_df = pd.DataFrame(stats[\"combined_graph\"]).T\n",
    "repost_stats_df = pd.DataFrame(stats[\"repost_graph\"]).T\n",
    "reply_stats_df = pd.DataFrame(stats[\"reply_graph\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the topic data\n",
    "bsky_topics = pd.read_csv(\"../data/bsky_df_id_topic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find root id for each repost id\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def find_root(G, child):\n",
    "    parent = list(G.predecessors(child))\n",
    "    if len(parent) == 0:\n",
    "        return child\n",
    "    else:\n",
    "        return find_root(G, parent[0])\n",
    "\n",
    "\n",
    "for repost_id in repost_stats_df.index:\n",
    "    if combined_graph.in_degree(repost_id) == 0:\n",
    "        repost_stats_df.loc[repost_id, \"root_id\"] = repost_id\n",
    "    else:\n",
    "        repost_stats_df.loc[repost_id, \"root_id\"] = find_root(combined_graph, repost_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_stats.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_original = repost_stats_df.merge(\n",
    "    bsky_topics, left_on=\"root_id\", right_on=\"id\", how=\"left\"\n",
    ").drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_original.to_csv(\"../data/bsky_repost_stat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_stats_df.reset_index(inplace=True)\n",
    "reply_original = reply_stats_df.merge(\n",
    "    bsky_topics, left_on=\"index\", right_on=\"id\", how=\"left\"\n",
    ").drop(columns=\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_original.to_csv(\"../data/bsky_reply_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats_df.reset_index(inplace=True)\n",
    "combined_original = combined_stats_df.merge(\n",
    "    bsky_topics, left_on=\"index\", right_on=\"id\", how=\"left\"\n",
    ").drop(columns=\"id\")\n",
    "\n",
    "combined_original.to_csv(\"../data/bsky_combined_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truthsocial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import json\n",
    "\n",
    "with open(\"../data/ts_threads_withReblogs.json\") as f:\n",
    "    ts_repost = json.load(f)\n",
    "\n",
    "with open(\"../data/ts_user_following_map.json\") as f:\n",
    "    ts_follow = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import cascade_analysis\n",
    "\n",
    "importlib.reload(cascade_analysis)\n",
    "\n",
    "cascade_graph = cascade_analysis.InformationCascadeGraph(ts_repost, ts_follow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d437b3a2ed2745ecb00f48b063d36899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Reply Graph:   0%|          | 0/1369696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reply_graph = cascade_graph.build_reply_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241c490787384c50bc2fef41414ee19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Repost Graph:   0%|          | 0/1369696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5217599\n"
     ]
    }
   ],
   "source": [
    "repost_graph = cascade_graph.build_repost_graph()\n",
    "print(repost_graph.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6703b2db215a4f8da7538f99aac7acaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/1325878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2.1: Merged 191575 reply edges into repost edges out of 747571 total reply edges\n",
      "Step 2.1: 0 nodes not in repost graph\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4004cb085a7443aca3130d545f254a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging:   0%|          | 0/3847903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_graph = cascade_graph.build_combined_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NX_CUGRAPH_AUTOCONFIG=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdca5bf98a043f6ba9ebf56db9cb597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Tree Statistics:   0%|          | 0/43818 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf4fd9664e44b5da16f56472d3cf8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Tree Statistics:   0%|          | 0/1369696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b390dbba20974f1da3cf0a2037c72916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Tree Statistics:   0%|          | 0/43818 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%env NX_CUGRAPH_AUTOCONFIG=True\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calculate_tree_statistics(graph):\n",
    "    if not nx.is_directed_acyclic_graph(graph):\n",
    "        raise ValueError(\"Graph must be a directed acyclic graph (DAG).\")\n",
    "\n",
    "    root_nodes = [n for n, d in graph.in_degree() if d == 0]\n",
    "    tree_statistics = {}\n",
    "\n",
    "    for root in tqdm(root_nodes, desc=\"Calculating Tree Statistics\"):\n",
    "        tree_nodes = nx.descendants(graph, root) | {root}\n",
    "        tree = graph.subgraph(tree_nodes)\n",
    "\n",
    "        depths = nx.single_source_shortest_path_length(tree, root)\n",
    "        max_depth = max(depths.values())\n",
    "\n",
    "        size = tree.number_of_nodes()\n",
    "\n",
    "        breadth = defaultdict(int)\n",
    "        for depth in depths.values():\n",
    "            breadth[depth] += 1\n",
    "        # Calculate max breadth\n",
    "        max_breadth = max(breadth.values())\n",
    "\n",
    "        total_distance = 0\n",
    "        pair_count = 0\n",
    "        for node in tree.nodes:\n",
    "            distances = nx.single_source_shortest_path_length(tree, node)\n",
    "            total_distance += sum(distances.values())\n",
    "            pair_count += len(distances) - 1\n",
    "\n",
    "        structural_virality = total_distance / pair_count if pair_count > 0 else 0\n",
    "\n",
    "        reach = len(tree.nodes)\n",
    "\n",
    "        tree_statistics[root] = {\n",
    "            \"max_depth\": max_depth,\n",
    "            \"size\": size,\n",
    "            \"breadth\": max_breadth,\n",
    "            \"structural_virality\": structural_virality,\n",
    "            \"reach\": reach,\n",
    "        }\n",
    "\n",
    "    return tree_statistics\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "import cudf\n",
    "import cugraph\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def calculate_tree_statistics_cugraph(nx_graph):\n",
    "    \"\"\"\n",
    "    Given a NetworkX DiGraph (assumed to be a tree or forest),\n",
    "    convert it to a cuGraph DiGraph and compute per-root tree statistics.\n",
    "\n",
    "    Statistics computed for each tree (root):\n",
    "    - max_depth: maximum distance from the root to any node\n",
    "    - size: number of nodes in the tree\n",
    "    - breadth: maximum number of nodes at any distance from the root\n",
    "    - structural_virality: average shortest-path distance among all node pairs in the tree\n",
    "    - reach: same as size\n",
    "    \"\"\"\n",
    "    # --- Step 1: Convert the NetworkX graph to a cuGraph graph ---\n",
    "    # Create an edge list from the NetworkX graph. cuGraph requires a DataFrame with\n",
    "    # source and destination columns.\n",
    "    df_edges = nx.to_pandas_edgelist(nx_graph)\n",
    "    # Make sure the edge list uses the expected column names: 'source' and 'target'\n",
    "    if \"source\" not in df_edges.columns or \"target\" not in df_edges.columns:\n",
    "        raise ValueError(\"The edge list must have 'source' and 'target' columns.\")\n",
    "\n",
    "    # Convert the Pandas DataFrame to a cuDF DataFrame.\n",
    "    cudf_edges = cudf.DataFrame.from_pandas(df_edges)\n",
    "\n",
    "    # Create a cuGraph DiGraph and load the edge list.\n",
    "    G_cu = cugraph.Graph(directed=True)\n",
    "    G_cu.from_cudf_edgelist(cudf_edges, source=\"source\", destination=\"target\")\n",
    "\n",
    "    # --- Step 2: Identify Root Nodes ---\n",
    "    # In a tree, root nodes have zero in-degree.\n",
    "    # We can compute in-degrees by grouping on the 'target' column.\n",
    "    in_degree_df = (\n",
    "        cudf_edges.groupby(\"target\")\n",
    "        .agg({\"target\": \"count\"})\n",
    "        .rename(columns={\"target\": \"in_degree\"})\n",
    "    )\n",
    "    # Get all unique vertices from both source and target columns.\n",
    "    all_vertices = pd.concat([df_edges[\"source\"], df_edges[\"target\"]]).unique()\n",
    "    # Identify roots: vertices that never appear as a target.\n",
    "    in_degree_set = set(in_degree_df[\"target\"].to_pandas())\n",
    "    roots = [v for v in all_vertices if v not in in_degree_set]\n",
    "\n",
    "    tree_statistics = {}\n",
    "    # --- Step 3: For Each Root, Run BFS and Compute Statistics ---\n",
    "    for root in tqdm(roots, desc=\"Calculating Tree Statistics (cuGraph)\"):\n",
    "        # Run BFS from the root; cuGraph returns a cuDF DataFrame with columns:\n",
    "        # 'vertex', 'distance', and 'predecessor'\n",
    "        bfs_result = cugraph.bfs(G_cu, root)\n",
    "        # Convert to Pandas DataFrame for easier (CPU-side) aggregation;\n",
    "        # if your trees are very large you might want to keep computations on the GPU.\n",
    "        bfs_pdf = bfs_result.to_pandas()\n",
    "\n",
    "        # max_depth: the maximum distance encountered\n",
    "        max_depth = int(bfs_pdf[\"distance\"].max())\n",
    "        # size (and reach): total number of nodes reached by BFS\n",
    "        size = len(bfs_pdf)\n",
    "        # breadth: maximum number of nodes found at the same distance from the root\n",
    "        breadth_series = bfs_pdf.groupby(\"distance\").size()\n",
    "        max_breadth = int(breadth_series.max())\n",
    "\n",
    "        # structural_virality: average distance over all node pairs.\n",
    "        # The following approach runs a BFS from each node in the tree.\n",
    "        # (Note: if the trees are large, you might want to use an approximate method.)\n",
    "        total_distance = 0\n",
    "        pair_count = 0\n",
    "        for v in bfs_pdf[\"vertex\"]:\n",
    "            bfs_v = cugraph.bfs(G_cu, v)\n",
    "            # Convert the result to Pandas for summing.\n",
    "            distances = bfs_v.to_pandas()[\"distance\"]\n",
    "            total_distance += distances.sum()\n",
    "            # Subtract one so that we don’t count the distance from v to itself\n",
    "            pair_count += len(distances) - 1\n",
    "        structural_virality = (\n",
    "            float(total_distance / pair_count) if pair_count > 0 else 0\n",
    "        )\n",
    "\n",
    "        tree_statistics[root] = {\n",
    "            \"max_depth\": max_depth,\n",
    "            \"size\": size,\n",
    "            \"breadth\": max_breadth,\n",
    "            \"structural_virality\": structural_virality,\n",
    "            \"reach\": size,\n",
    "        }\n",
    "\n",
    "    return tree_statistics\n",
    "\n",
    "\n",
    "reply_stats = calculate_tree_statistics(reply_graph)\n",
    "repost_stats = calculate_tree_statistics(repost_graph)\n",
    "combined_stats = calculate_tree_statistics(combined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cugraph' has no attribute 'DiGraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reply_stats \u001b[38;5;241m=\u001b[39m \u001b[43mcascade_analysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInformationCascadeGraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_tree_statistics_cugraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m repost_stats \u001b[38;5;241m=\u001b[39m cascade_analysis\u001b[38;5;241m.\u001b[39mInformationCascadeGraph\u001b[38;5;241m.\u001b[39mcalculate_tree_statistics_cugraph(repost_graph)\n\u001b[1;32m      3\u001b[0m combined_stats \u001b[38;5;241m=\u001b[39m cascade_analysis\u001b[38;5;241m.\u001b[39mInformationCascadeGraph\u001b[38;5;241m.\u001b[39mcalculate_tree_statistics_cugraph(combined_graph)\n",
      "File \u001b[0;32m~/projects/information-diffusion/src/cascade_analysis.py:314\u001b[0m, in \u001b[0;36mInformationCascadeGraph.calculate_tree_statistics_cugraph\u001b[0;34m(nx_graph)\u001b[0m\n\u001b[1;32m    311\u001b[0m cudf_edges \u001b[38;5;241m=\u001b[39m cudf\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_pandas(df_edges)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Create a cuGraph DiGraph and load the edge list.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m G_cu \u001b[38;5;241m=\u001b[39m \u001b[43mcugraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiGraph\u001b[49m()\n\u001b[1;32m    315\u001b[0m G_cu\u001b[38;5;241m.\u001b[39mfrom_cudf_edgelist(cudf_edges, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m, destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# --- Step 2: Identify Root Nodes ---\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# In a tree, root nodes have zero in-degree.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# We can compute in-degrees by grouping on the 'target' column.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cugraph' has no attribute 'DiGraph'"
     ]
    }
   ],
   "source": [
    "reply_stats = (\n",
    "    cascade_analysis.InformationCascadeGraph.calculate_tree_statistics_cugraph(\n",
    "        reply_graph\n",
    "    )\n",
    ")\n",
    "repost_stats = (\n",
    "    cascade_analysis.InformationCascadeGraph.calculate_tree_statistics_cugraph(\n",
    "        repost_graph\n",
    "    )\n",
    ")\n",
    "combined_stats = (\n",
    "    cascade_analysis.InformationCascadeGraph.calculate_tree_statistics_cugraph(\n",
    "        combined_graph\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_stats = cascade_graph.calculate_tree_statistics(reply_graph)\n",
    "repost_stats = cascade_graph.calculate_tree_statistics(repost_graph)\n",
    "combined_stats = cascade_graph.calculate_tree_statistics(combined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reply_stats_df = pd.DataFrame(reply_stats).T\n",
    "repost_stats_df = pd.DataFrame(repost_stats).T\n",
    "combined_stats_df = pd.DataFrame(combined_stats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find root id for each repost id\n",
    "import networkx as nx\n",
    "\n",
    "repost_root = []\n",
    "\n",
    "\n",
    "def find_root(G, child):\n",
    "    parent = list(G.predecessors(child))\n",
    "    if len(parent) == 0:\n",
    "        return child\n",
    "    else:\n",
    "        return find_root(G, parent[0])\n",
    "\n",
    "\n",
    "for repost_id in repost_stats_df.index:\n",
    "    if combined_graph.in_degree(repost_id) == 0:\n",
    "        repost_stats_df.loc[repost_id, \"root_id\"] = repost_id\n",
    "    else:\n",
    "        repost_stats_df.loc[repost_id, \"root_id\"] = find_root(combined_graph, repost_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_topics = pd.read_csv(\"../data/ts_df_id_topic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_stats_df.reset_index(inplace=True)\n",
    "reply_stats_df[\"index\"] = reply_stats_df[\"index\"].astype(int)\n",
    "ts_topics[\"id\"] = ts_topics[\"id\"].astype(int)\n",
    "reply_stats_df = reply_stats_df.merge(\n",
    "    ts_topics, left_on=\"index\", right_on=\"id\", how=\"left\"\n",
    ").drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_stats_df.to_csv(\"../data/ts_reply_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_stats_df.reset_index(inplace=True)\n",
    "repost_stats_df[\"root_id\"] = repost_stats_df[\"root_id\"].astype(int)\n",
    "repost_stats_df[\"index\"] = repost_stats_df[\"index\"].astype(int)\n",
    "ts_topics[\"id\"] = ts_topics[\"id\"].astype(int)\n",
    "\n",
    "repost_stats_df_test = repost_stats_df.merge(\n",
    "    ts_topics, left_on=\"root_id\", right_on=\"id\", how=\"left\"\n",
    ").drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repost_stats_df_test.to_csv(\"../data/ts_repost_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats_df.reset_index(inplace=True)\n",
    "combined_stats_df[\"index\"] = combined_stats_df[\"index\"].astype(int)\n",
    "ts_topics[\"id\"] = ts_topics[\"id\"].astype(int)\n",
    "combined_stats_df_output = combined_stats_df.merge(\n",
    "    ts_topics, left_on=\"index\", right_on=\"id\", how=\"left\"\n",
    ").drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats_df_output.to_csv(\"../data/ts_combined_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
